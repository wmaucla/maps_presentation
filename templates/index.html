<!doctype html>
<html>
	<head>
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-160747063-4"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'UA-160747063-4');
		</script>


		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="{{ url_for('static', filename='css/reveal.css') }}">
		<link rel="stylesheet" href="{{ url_for('static', filename='css/theme/serif.css') }}">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="{{ url_for('static', filename='lib/css/zenburn.css') }}">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section name="Introduction">
					<section>
						<h1> MAPS - ML for APS </h1>
					</section>
				</section>
				<section name="Business Objective">
					<section>
						<h2> Business Objective </h2>
					</section>
					<section>
						Attending Physician Statements (APS) provide lots of useful patient data in pdf form. We want to extract useful information in order to help inform underwriting decisions.
					</section>
					<section>
						<img src="{{ url_for('static', filename='images/maps_overview.png') }}" style="margin:0; border:0">
					</section>
					<section>
						<p>
							For POC, exploring <b> diagnosis extraction </b> specifically - finding the patient's diagnosis(es) within an APS
						</p>
					</section>
				</section>
				<section name="Pipelining">
					<section>
						<h2> Pipelining </h2>
						<p> Everyone needs it, no one wants to do it </p>
					</section>
					<section>
						<img src="{{ url_for('static', filename='images/metaflow.png') }}" style="width:40%; margin:0; border:0">
						<p> A framework for real-life data science - from Netflix </p>
						</p>
					</section>
					<section>
						<h3> Metaflow Review </h3>
						<ul>
							<li> Pros: Lightweight setup / learning curve, separate namespaces, data science focused </li>
							<li> Cons: no native Azure support, no scheduler, hard to customize flows </li>
						</ul>
					</section>
					<section>
						<h3> ML Management - Thoughts </h3>
						<ul>
							<li class="fragment"> Metaflow: better for smaller DS-specific projects with AWS and straightforward flows </li>
							<li class="fragment"> MLFlow: mostly suited for tracking model versions, not pipelines </li>
							<li class="fragment"> Luigi: most intuitive, good for simpler ETL pipelines  </li>
							<li class="fragment"> Airflow: good overall for larger projects w/ larger complexity  </li>
							<li class="fragment"> Kubeflow: perhaps best suited overall; separate docker containers ideal and good for deployment </li>
							<li class="fragment"> Flyte: ? </li>
						</ul>
					</section>
				</section>
				<section name="Question Answer">
					<section>
						<h2> Question Answer </h2>
						<p style="font-size:60%">
							'Cause when you ask a question, you expect an answer. That's the way it works... question, answer, answer, question. If he gave the answer, I'd have to come up with the question. That would be Jeopardy. That's wrong. </br> <i> Colin Mochrie, Whose Line is It Anyway</i>
						</p>
					</section>
					<section>
						Try it out <a href="https://gqjfkrpn07.execute-api.us-west-2.amazonaws.com/prod/qa_page"> here </a> with the following text
						<p>
							Question answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.
						</p>
					</section>
					<section>
						<img src="{{ url_for('static', filename='images/huggingface_logo.svg') }}" style="margin:0; border:0">
						<p> Powered by huggingface transformers</p>
					</section>
					<section>
						<h3> BERT Models </h3>
						<p> Pretrained models are a way of life </p>
						<ul>
							<li> Default BERT fine-tuned on SQUAD </li>
							<li> BioBERT - pre-trained biomedical language representation model for biomedical text mining </li>
							<li> SciBERT - trained on papers from the corpus of semanticscholar.org </li>
						</ul>
					</section>
					<section>
						<img src="{{ url_for('static', filename='images/qa_good_bad.png') }}" style="height:150%; width:150%; margin:0; border:0">
					</section>
					<section>
						<h3> Why QA? </h3>
						<ul>
							<li> Also QuickUMLS - a tool for fast, unsupervised biomedical concept extraction from medical text w/ approximate string matching  </li>
							<li class="fragment"> Hope to extend QA to other use cases - e.g. extracting dates - and long term be made available to underwriters </li>
							<li class="fragment"> Much better at handling spelling mistakes compared to spellcheckers or QuickUMLS </li>
							<li class="fragment"> Context matters heavily </li>
						</ul>
					</section>
					<section>
						<h3> Challenges </h3>
						<ul>
							<li> Negation detection </li>
							<li> Multiple diagnosis </li>
							<li> Different formats </li>
							<li> <b> OCR quality </b> </li>
						</ul>
					</section>
				</section>
				<section name="Image Modelling">
					<section>
						<h2> Image Classification </h2>
					</section>
					<section>
						<img src="{{ url_for('static', filename='images/image_classification.png') }}" style="margin:0; border:0">
					</section>
					<section>
						<img src="{{ url_for('static', filename='images/pytorch_logo.png') }}" style="margin:0; border:0">
						<p> Classification model based on pytorch pretrained models - categories like lists, paragraph-based text </p>
					</section>
					<section>
						<p> Models built for classification works well at the moment, with a lot more work to be done tackling challenges like handwriting, tables, check boxes, etc. </p>
					</section>
				</section>
				<section name="OCR">
					<section>
						<h2> Tesseract OCR </h2>
					</section>
					<section>
						<p> Used Tesseract due to open source - other alternatives would require us sending patient information to third parties. Experimented with fine-tuning and adding custom vocab to Tesseract models with minor improvements </p>
					</section>
					<section>
						<img src="{{ url_for('static', filename='images/open_cv.png') }}" style="width:40%; margin:0; border:0">
						<p> Adding OpenCV for image processing prior to Tesseract - morphological + thresholding operations help </p>
					</section>
					<section>
						<p> Conclusion: biggest challenges come from poor OCR due to faded text from scanned pdfs - what else can be done? </p>
					</section>
				</section>
				<section name="Frontier">
					<section>
						<h2> On the Frontier </h2>
					</section>
					<section>
						<h3> Visual Question Answer </h3>
						<img src="{{ url_for('static', filename='images/pythia.jpeg') }}" style="width:75%; margin:0; border:0">
						<p> Pythia, from FB Engineering </p>
					</section>
					<section>
						<h3> Rosetta </h3>
						<img src="{{ url_for('static', filename='images/rosetta.png') }}" style="width:80%; margin:0; border:0">
					</section>
					<section>
						<p> Special shout out to PapersWithCode and the number of random papers I've looked at as well (Sentence BERT, multitask learning, ...) </p>
						<img src="{{ url_for('static', filename='images/papers_meme.jpg') }}" style="width:60%; margin:0; border:0">
					</section>
				</section>
				<section>
					<section>
						<h2> Summary </h2>
					</section>
					<section>
						<img src="{{ url_for('static', filename='images/tech_stack_maps.png') }}" style="margin:0; border:0">
					</section>
				</section>
				</section>
			</div>
		</div>

		<script src="{{ url_for('static', filename='lib/js/head.min.js') }}"></script>
		<script src="{{ url_for('static', filename='js/reveal.js') }}"></script>

		<script>
			Reveal.initialize({
				math: {
					mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
					config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
				},
				dependencies: [
					{ src: 'static/plugin/markdown/marked.js' },
					{ src: 'static/plugin/markdown/markdown.js' },
					{ src: 'static/plugin/notes/notes.js', async: true },
					{ src: 'static/plugin/math/math.js', async: true },
					{ src: 'static/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
